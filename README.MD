# Multilingual Question Answering

## Componenets
We have implemented two componenet in this:

1. Translation
2. Question and Answering

## Objective
Helping people from regional areas, who are struggling to understand English. Through this project we are trying to answer questions which are asked in regional languages.

## Models

1. LSTM attention model for Translation.
2. BERT Transformer for Question & Answering.

## Metrics:
1. BLEU Score for evaluate translation. 
2. Precision, Recall and Accuracy for Question and Answering.

## Model Architecture:

### Translation:

![image](https://user-images.githubusercontent.com/12909004/185725520-20cb2152-6ca0-41d0-b619-81315d8e146c.png)

### QnA Models:

![image](https://user-images.githubusercontent.com/12909004/185725555-a2191e9a-bf82-449c-8a50-f40c4eb1d945.png)


## Results:

![image](https://user-images.githubusercontent.com/12909004/185725550-d36efd6a-6693-443b-a09d-f5ca620d2d04.png)

![image](https://user-images.githubusercontent.com/12909004/185725566-cd5d1287-0e3b-40d5-b12e-c405628ad630.png)

## Combined Model Results:

![image](https://user-images.githubusercontent.com/12909004/185725582-8584be12-529d-461b-ad59-75389b994c82.png)

